{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Continuous Variables\n",
    "\n",
    "This tutorial will present various methods on how to preprocess continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap on UCI Breast Cancer Dataset (breast.data)\n",
    "\n",
    "* Easy dataset to start off with\n",
    "* Dataset contains all continuous variables, except one ID column, and one label (M, B) column\n",
    "    * The continous variables are just statistics collected from a tumor's biopsy\n",
    "    * More information can be found [here](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names)\n",
    "* Goal of the dataset is to classify whether a tumor is maligant (M) or benigh (B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prefix = \"../datasets/\"\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(prefix + \"breast.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9    ...        22     23      24      25      26      27      28  \\\n",
       "0  0.14710   ...     25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119   \n",
       "1  0.07017   ...     24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416   \n",
       "2  0.12790   ...     23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504   \n",
       "3  0.10520   ...     14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869   \n",
       "4  0.10430   ...     22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000   \n",
       "\n",
       "       29      30       31  \n",
       "0  0.2654  0.4601  0.11890  \n",
       "1  0.1860  0.2750  0.08902  \n",
       "2  0.2430  0.3613  0.08758  \n",
       "3  0.2575  0.6638  0.17300  \n",
       "4  0.1625  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(0, axis=1, inplace=True)\n",
    "\n",
    "# Shuffling dataset\n",
    "import numpy as np\n",
    "perm = np.random.permutation(len(df))\n",
    "df = df.iloc[perm]\n",
    "\n",
    "# Creating features and response variable set\n",
    "y = df[1]\n",
    "X = df.drop(1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM:  0.713286713287\n",
      "Accuracy of Logistic Regression:  0.944055944056\n"
     ]
    }
   ],
   "source": [
    "predictions = SVC().fit(X_train, y_train).predict(X_test)\n",
    "non_scale_accuracy = accuracy_score(y_test, predictions)\n",
    "print \"Accuracy of SVM: \", non_scale_accuracy\n",
    "\n",
    "predictions = LogisticRegression().fit(X_train, y_train).predict(X_test)\n",
    "non_scale_accuracy = accuracy_score(y_test, predictions)\n",
    "print \"Accuracy of Logistic Regression: \", non_scale_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the classification rate by feature engineering\n",
    "\n",
    "In general, we're not getting the bang for our buck using the support vector machine. And it's because we're not preprocessing the continuous features correctly.\n",
    "\n",
    "A variety of ways to improve model accuracy with continuous features\n",
    "\n",
    "* Feature scaling\n",
    "    * Standard scaling: For each continuous feature, $\\mu = 0$ and $\\sigma = 1$\n",
    "    * Simple scaling: Scale all continuous features between the range $[0, 1]$ or $[-1, 1]$.\n",
    "* Univariate feature selection\n",
    "    * Univariate feature selection using $p$-values\n",
    "    * Correlation based feature selection using Spearman Rho or Kendall Tau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Feature scaling\n",
    "\n",
    "* Idea is that continuous features can take anywhere in a certain range; need a way to shrink (or inflate) everything\n",
    "* Reduce the variation in the dataset using scaling.\n",
    "* **Standard scaling** applies the following formula to transform a feature into a space with mean 0 and standard deviation 1. This is also called \"recentering\" the dataset.\n",
    "\n",
    "    Given the $i$th continuous feature $X_i$, we apply the following formula for each $x \\in X_i$:\n",
    "    $$x' = \\frac{x - \\bar{X_i}}{\\sigma_{X_i}}$$\n",
    "    where $\\bar{X_i}$ is the mean of feature $X_i$ and $\\sigma_{X_i}$ is its standard deviation. Our new dataset composed of $x'$ will have mean 0 and standard deviation 1.\n",
    "* **Min-max scaling** applies the following formula to shrink (or inflate) features into a space between a given interval. If we want our features to lie within the interval [0, 1], the following formula would work.\n",
    "    $$x' = \\frac{x - \\min(X_i)}{\\max(X_i) - \\min(X_i)}$$\n",
    "\n",
    "* More information on [Wikipedia](https://en.wikipedia.org/wiki/Feature_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>9.731</td>\n",
       "      <td>15.34</td>\n",
       "      <td>63.78</td>\n",
       "      <td>300.2</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.41080</td>\n",
       "      <td>0.07857</td>\n",
       "      <td>0.2548</td>\n",
       "      <td>0.09296</td>\n",
       "      <td>...</td>\n",
       "      <td>11.02</td>\n",
       "      <td>19.49</td>\n",
       "      <td>71.04</td>\n",
       "      <td>380.5</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.27720</td>\n",
       "      <td>0.82160</td>\n",
       "      <td>0.15710</td>\n",
       "      <td>0.3108</td>\n",
       "      <td>0.12590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>14.580</td>\n",
       "      <td>21.53</td>\n",
       "      <td>97.41</td>\n",
       "      <td>644.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.18680</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.08783</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.06924</td>\n",
       "      <td>...</td>\n",
       "      <td>17.62</td>\n",
       "      <td>33.21</td>\n",
       "      <td>122.40</td>\n",
       "      <td>896.9</td>\n",
       "      <td>0.15250</td>\n",
       "      <td>0.66430</td>\n",
       "      <td>0.55390</td>\n",
       "      <td>0.27010</td>\n",
       "      <td>0.4264</td>\n",
       "      <td>0.12750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>15.280</td>\n",
       "      <td>22.41</td>\n",
       "      <td>98.92</td>\n",
       "      <td>710.6</td>\n",
       "      <td>0.09057</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.05375</td>\n",
       "      <td>0.03263</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.06317</td>\n",
       "      <td>...</td>\n",
       "      <td>17.80</td>\n",
       "      <td>28.03</td>\n",
       "      <td>113.80</td>\n",
       "      <td>973.1</td>\n",
       "      <td>0.13010</td>\n",
       "      <td>0.32990</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.09772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>14.990</td>\n",
       "      <td>25.20</td>\n",
       "      <td>95.54</td>\n",
       "      <td>698.8</td>\n",
       "      <td>0.09387</td>\n",
       "      <td>0.05131</td>\n",
       "      <td>0.02398</td>\n",
       "      <td>0.02899</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>0.05504</td>\n",
       "      <td>...</td>\n",
       "      <td>14.99</td>\n",
       "      <td>25.20</td>\n",
       "      <td>95.54</td>\n",
       "      <td>698.8</td>\n",
       "      <td>0.09387</td>\n",
       "      <td>0.05131</td>\n",
       "      <td>0.02398</td>\n",
       "      <td>0.02899</td>\n",
       "      <td>0.1565</td>\n",
       "      <td>0.05504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>13.470</td>\n",
       "      <td>14.06</td>\n",
       "      <td>87.32</td>\n",
       "      <td>546.3</td>\n",
       "      <td>0.10710</td>\n",
       "      <td>0.11550</td>\n",
       "      <td>0.05786</td>\n",
       "      <td>0.05266</td>\n",
       "      <td>0.1779</td>\n",
       "      <td>0.06639</td>\n",
       "      <td>...</td>\n",
       "      <td>14.83</td>\n",
       "      <td>18.32</td>\n",
       "      <td>94.94</td>\n",
       "      <td>660.2</td>\n",
       "      <td>0.13930</td>\n",
       "      <td>0.24990</td>\n",
       "      <td>0.18480</td>\n",
       "      <td>0.13350</td>\n",
       "      <td>0.3227</td>\n",
       "      <td>0.09326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2      3      4      5        6        7        8        9       10  \\\n",
       "152   9.731  15.34  63.78  300.2  0.10720  0.15990  0.41080  0.07857  0.2548   \n",
       "26   14.580  21.53  97.41  644.8  0.10540  0.18680  0.14250  0.08783  0.2252   \n",
       "184  15.280  22.41  98.92  710.6  0.09057  0.10520  0.05375  0.03263  0.1727   \n",
       "38   14.990  25.20  95.54  698.8  0.09387  0.05131  0.02398  0.02899  0.1565   \n",
       "482  13.470  14.06  87.32  546.3  0.10710  0.11550  0.05786  0.05266  0.1779   \n",
       "\n",
       "          11   ...        22     23      24     25       26       27       28  \\\n",
       "152  0.09296   ...     11.02  19.49   71.04  380.5  0.12920  0.27720  0.82160   \n",
       "26   0.06924   ...     17.62  33.21  122.40  896.9  0.15250  0.66430  0.55390   \n",
       "184  0.06317   ...     17.80  28.03  113.80  973.1  0.13010  0.32990  0.36300   \n",
       "38   0.05504   ...     14.99  25.20   95.54  698.8  0.09387  0.05131  0.02398   \n",
       "482  0.06639   ...     14.83  18.32   94.94  660.2  0.13930  0.24990  0.18480   \n",
       "\n",
       "          29      30       31  \n",
       "152  0.15710  0.3108  0.12590  \n",
       "26   0.27010  0.4264  0.12750  \n",
       "184  0.12260  0.3175  0.09772  \n",
       "38   0.02899  0.1565  0.05504  \n",
       "482  0.13350  0.3227  0.09326  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM using StandardScaler: 0.986013986014\n",
      "Accuracy of SVM using MinMaxScaler: 0.958041958042\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# I want to show that SVMs are sensitive to feature scaling.\n",
    "# In partcular, because sklearn.svm.SVC uses the RBF kernel, this kernel\n",
    "# is sensitive to scaling.\n",
    "#\n",
    "# More information on how to properly train an SVM is here:\n",
    "#    http://www.csie.ntu.edu.tw/~cjlin/papers/guide/guide.pdf\n",
    "\n",
    "for Scaler in [StandardScaler, MinMaxScaler]:\n",
    "    \n",
    "    # \"Scaler\" is a class object whose constructor and attributes we can call\n",
    "    scaler = Scaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    \n",
    "    svm = SVC().fit(X_train_scaled, y_train)\n",
    "    \n",
    "    X_test_scaled = scaler.transform(X_test)  # Note we don't \"refit\" for testing data\n",
    "    predictions = svm.predict(X_test_scaled)\n",
    "    print \"Accuracy of SVM using {0}: {1}\".format(Scaler.__name__, accuracy_score(y_test, predictions))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Selection\n",
    "    \n",
    "Idea is that we have all of these continuous attributes.... who is to say that any of them are useful?\n",
    "\n",
    "The full Scikit-Learn module on feature selection is presented [here](http://scikit-learn.org/stable/modules/feature_selection.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## UCI Sonar Dataset\n",
    "\n",
    "* The task is to train a classifier to discriminate between sonar signals bounced off a metal cylinder and those bounced off a roughly cylindrical rock. (From website.)\n",
    "* More dataset description [here](https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.names)\n",
    "* In general, this is one of my favorite datasets because the classification task is difficult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(prefix + \"sonar.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9  ...      51      52      53      54      55      56      57      58  \\\n",
       "0  0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090   \n",
       "1  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
       "2  0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
       "3  0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
       "4  0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
       "\n",
       "       59  60  \n",
       "0  0.0032   R  \n",
       "1  0.0044   R  \n",
       "2  0.0078   R  \n",
       "3  0.0117   R  \n",
       "4  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The class labels (R, M) are not shuffled, so we have to shuffle them\n",
    "import numpy as np\n",
    "perm = np.random.permutation(len(df))\n",
    "df = df.loc[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(60, axis=1)\n",
    "y = df[60]  # Rock or mine class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0391</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.0668</td>\n",
       "      <td>0.0609</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.1161</td>\n",
       "      <td>0.0663</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6       7       8   \\\n",
       "56  0.0152  0.0102  0.0113  0.0263  0.0097  0.0391  0.0857  0.0915  0.0949   \n",
       "24  0.0293  0.0644  0.0390  0.0173  0.0476  0.0816  0.0993  0.0315  0.0736   \n",
       "42  0.0211  0.0319  0.0415  0.0286  0.0121  0.0438  0.1299  0.1390  0.0695   \n",
       "54  0.0132  0.0080  0.0188  0.0141  0.0436  0.0668  0.0609  0.0131  0.0899   \n",
       "67  0.0368  0.0403  0.0317  0.0293  0.0820  0.1342  0.1161  0.0663  0.0155   \n",
       "\n",
       "        9    ...        50      51      52      53      54      55      56  \\\n",
       "56  0.1504   ...    0.0048  0.0049  0.0041  0.0036  0.0013  0.0046  0.0037   \n",
       "24  0.0860   ...    0.0170  0.0035  0.0052  0.0083  0.0078  0.0075  0.0105   \n",
       "42  0.0568   ...    0.0053  0.0090  0.0042  0.0153  0.0106  0.0020  0.0105   \n",
       "54  0.0922   ...    0.0136  0.0044  0.0028  0.0021  0.0022  0.0048  0.0138   \n",
       "67  0.0506   ...    0.0058  0.0091  0.0160  0.0160  0.0081  0.0070  0.0135   \n",
       "\n",
       "        57      58      59  \n",
       "56  0.0011  0.0034  0.0033  \n",
       "24  0.0160  0.0095  0.0011  \n",
       "42  0.0049  0.0070  0.0080  \n",
       "54  0.0140  0.0028  0.0064  \n",
       "67  0.0067  0.0078  0.0068  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As a baseline, let's classify this with Logistic Regression, no scaling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.2079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>0.1850</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>0.4117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.1563</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.1182</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.2318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "152  0.0131  0.0201  0.0045  0.0217  0.0230  0.0481  0.0742  0.0333  0.1369   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "185  0.0340  0.0625  0.0381  0.0257  0.0441  0.1027  0.1287  0.1850  0.2647   \n",
       "155  0.0211  0.0128  0.0015  0.0450  0.0711  0.1563  0.1518  0.1206  0.1666   \n",
       "163  0.0072  0.0027  0.0089  0.0061  0.0420  0.0865  0.1182  0.0999  0.1976   \n",
       "\n",
       "         9    ...        50      51      52      53      54      55      56  \\\n",
       "152  0.2079   ...    0.0111  0.0168  0.0086  0.0045  0.0062  0.0065  0.0030   \n",
       "1    0.2872   ...    0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n",
       "185  0.4117   ...    0.0329  0.0141  0.0019  0.0067  0.0099  0.0042  0.0057   \n",
       "155  0.1345   ...    0.0174  0.0117  0.0023  0.0047  0.0049  0.0031  0.0024   \n",
       "163  0.2318   ...    0.0092  0.0078  0.0071  0.0081  0.0034  0.0064  0.0037   \n",
       "\n",
       "         57      58      59  \n",
       "152  0.0066  0.0029  0.0053  \n",
       "1    0.0049  0.0052  0.0044  \n",
       "185  0.0051  0.0033  0.0058  \n",
       "155  0.0039  0.0051  0.0015  \n",
       "163  0.0036  0.0012  0.0037  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression:  0.75\n"
     ]
    }
   ],
   "source": [
    "predictions = LogisticRegression().fit(X_train, y_train).predict(X_test)\n",
    "print \"Accuracy of Logistic Regression: \", accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Overall, want to see if univariate feature selection works with this dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression:  0.807692307692 \t shape is  (52, 1)\n",
      "Accuracy of Logistic Regression:  0.807692307692 \t shape is  (52, 2)\n",
      "Accuracy of Logistic Regression:  0.711538461538 \t shape is  (52, 4)\n",
      "Accuracy of Logistic Regression:  0.730769230769 \t shape is  (52, 6)\n",
      "Accuracy of Logistic Regression:  0.730769230769 \t shape is  (52, 9)\n",
      "Accuracy of Logistic Regression:  0.75 \t shape is  (52, 12)\n",
      "Accuracy of Logistic Regression:  0.75 \t shape is  (52, 18)\n",
      "Accuracy of Logistic Regression:  0.807692307692 \t shape is  (52, 24)\n",
      "Accuracy of Logistic Regression:  0.807692307692 \t shape is  (52, 36)\n",
      "Accuracy of Logistic Regression:  0.846153846154 \t shape is  (52, 48)\n",
      "Accuracy of Logistic Regression:  0.769230769231 \t shape is  (52, 60)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "transform = SelectPercentile(score_func=f_classif)\n",
    "percentiles = (1, 3, 6, 10, 15, 20, 30, 40, 60, 80, 100)\n",
    "for percentile in percentiles:\n",
    "    transform.set_params(percentile=percentile)\n",
    "    \n",
    "    X_train_altered = transform.fit_transform(X_train, y_train)\n",
    "    X_test_altered = transform.transform(X_test)\n",
    "    \n",
    "    predictions = LogisticRegression().fit(X_train_altered, y_train).predict(X_test_altered)\n",
    "    print \"Accuracy of Logistic Regression: \", accuracy_score(predictions, y_test), \"\\t shape is \", X_test_altered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 60)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test#Examples\n",
    "http://scikit-learn.org/stable/auto_examples/feature_selection/plot_feature_selection.html\n",
    "http://scikit-learn.org/stable/auto_examples/svm/plot_svm_anova.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAEZCAYAAADxH64ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlDxFRERK9P926f2Kb7M1VAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115803a50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets, feature_selection, cross_validation\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "###############################################################################\n",
    "# Import some data to play with\n",
    "digits = datasets.load_digits()\n",
    "y = digits.target\n",
    "# Throw away data, to be in the curse of dimension settings\n",
    "y = y[:200]\n",
    "X = digits.data[:200]\n",
    "n_samples = len(y)\n",
    "X = X.reshape((n_samples, -1))\n",
    "# add 200 non-informative features\n",
    "X = np.hstack((X, 2 * np.random.random((n_samples, 200))))\n",
    "\n",
    "###############################################################################\n",
    "# Create a feature-selection transform and an instance of SVM that we\n",
    "# combine together to have an full-blown estimator\n",
    "\n",
    "transform = feature_selection.SelectPercentile(feature_selection.f_classif)\n",
    "\n",
    "#clf = Pipeline([('anova', transform), ('svc', svm.SVC(C=1.0))])\n",
    "\n",
    "###############################################################################\n",
    "# Plot the cross-validation score as a function of percentile of features\n",
    "score_means = list()\n",
    "score_stds = list()\n",
    "percentiles = (1, 3, 6, 10, 15, 20, 30, 40, 60, 80, 100)\n",
    "\n",
    "for percentile in percentiles:\n",
    "    \n",
    "    transform.set_params(percentile=percentile)\n",
    "    X_altered = transform.fit_transform(X, y)\n",
    "    \n",
    "    #clf.set_params(anova__percentile=percentile)\n",
    "    # Compute cross-validation score using all CPUs\n",
    "    this_scores = cross_validation.cross_val_score(svm.SVC(C=1.0), X_altered, y, n_jobs=1)\n",
    "    score_means.append(this_scores.mean())\n",
    "    score_stds.append(this_scores.std())\n",
    "\n",
    "plt.errorbar(percentiles, score_means, np.array(score_stds))\n",
    "\n",
    "plt.title(\n",
    "    'Performance of the SVM-Anova varying the percentile of features selected')\n",
    "plt.xlabel('Percentile')\n",
    "plt.ylabel('Prediction rate')\n",
    "\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAEZCAYAAADxH64ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0/8HSgXsWj0a11gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115a9a1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets, feature_selection, cross_validation\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "###############################################################################\n",
    "# Import some data to play with\n",
    "digits = datasets.load_digits()\n",
    "y = digits.target\n",
    "# Throw away data, to be in the curse of dimension settings\n",
    "y = y[:200]\n",
    "X = digits.data[:200]\n",
    "n_samples = len(y)\n",
    "X = X.reshape((n_samples, -1))\n",
    "# add 200 non-informative features\n",
    "X = np.hstack((X, 2 * np.random.random((n_samples, 200))))\n",
    "\n",
    "###############################################################################\n",
    "# Create a feature-selection transform and an instance of SVM that we\n",
    "# combine together to have an full-blown estimator\n",
    "\n",
    "transform = feature_selection.SelectPercentile(feature_selection.f_classif)\n",
    "\n",
    "clf = Pipeline([('anova', transform), ('svc', svm.SVC(C=1.0))])\n",
    "\n",
    "###############################################################################\n",
    "# Plot the cross-validation score as a function of percentile of features\n",
    "score_means = list()\n",
    "score_stds = list()\n",
    "percentiles = (1, 3, 6, 10, 15, 20, 30, 40, 60, 80, 100)\n",
    "\n",
    "for percentile in percentiles:\n",
    "    clf.set_params(anova__percentile=percentile)\n",
    "    # Compute cross-validation score using all CPUs\n",
    "    this_scores = cross_validation.cross_val_score(clf, X, y, n_jobs=1)\n",
    "    score_means.append(this_scores.mean())\n",
    "    score_stds.append(this_scores.std())\n",
    "\n",
    "plt.errorbar(percentiles, score_means, np.array(score_stds))\n",
    "\n",
    "plt.title(\n",
    "    'Performance of the SVM-Anova varying the percentile of features selected')\n",
    "plt.xlabel('Percentile')\n",
    "plt.ylabel('Prediction rate')\n",
    "\n",
    "plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
