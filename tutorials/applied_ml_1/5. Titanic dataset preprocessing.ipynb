{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = \"../datasets/titanic/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(prefix + \"train.csv\")\n",
    "labels = pd.read_csv(prefix + \"genderclassmodel.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset information\n",
    "\n",
    "From [here](https://www.kaggle.com/c/titanic/data).\n",
    "\n",
    "```\n",
    "VARIABLE DESCRIPTIONS:\n",
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "SPECIAL NOTES:\n",
    "Pclass is a proxy for socio-economic status (SES)\n",
    " 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n",
    "\n",
    "Age is in Years; Fractional if Age less than One (1)\n",
    " If the Age is Estimated, it is in the form xx.5\n",
    "\n",
    "With respect to the family relation variables (i.e. sibsp and parch)\n",
    "some relations were ignored.  The following are the definitions used\n",
    "for sibsp and parch.\n",
    "\n",
    "Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\n",
    "Parent:   Mother or Father of Passenger Aboard Titanic\n",
    "Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n",
    "\n",
    "Other family relatives excluded from this study include cousins,\n",
    "nephews/nieces, aunts/uncles, and in-laws.  Some children travelled\n",
    "only with a nanny, therefore parch=0 for them.  As well, some\n",
    "travelled with very close friends or neighbors in a village, however,\n",
    "the definitions do not support such relations.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_nan(df):\n",
    "    \"\"\"Counts the missing (NaN) values in a dataframe. Returns a \n",
    "    pandas.Series object that indicates the number of NaN values\n",
    "    per row.\n",
    "    \n",
    "    http://stackoverflow.com/a/26266451/2014591\n",
    "    \"\"\"\n",
    "    return df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_nan(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Try a simple model. Use only 4 features.\n",
    "features = [\"Pclass\", \"Sex\", \"Fare\", \"Embarked\", \"Survived\"]\n",
    "subset = data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = subset[\"Survived\"]\n",
    "X = subset.drop(\"Survived\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The quick and easy experimentation procedure\n",
    "\n",
    "1. Make your train test split\n",
    "2. Encode the categorical variables, scale the variables\n",
    "3. Fit and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing who lived or died, based upon fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a histogram of the fares\n",
    "# http://stackoverflow.com/a/6873956/2014591   <- plotting two histograms at once\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Way to change sizes of plots\n",
    "# http://stackoverflow.com/a/332311/2014591\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 8, 5  \n",
    "\n",
    "survived = X_train[y_train == 1]\n",
    "died = X_train[y_train == 0]\n",
    "\n",
    "# Remove more data\n",
    "survived = survived[~(survived[\"Fare\"] > 300)]\n",
    "\n",
    "# http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.hist\n",
    "plt.hist([survived[\"Fare\"], died[\"Fare\"]], alpha=0.5, color=['g', 'r'], label=[\"Survived\", \"Died\"], bins=10, stacked=True)\n",
    "plt.xlabel(\"Fare\")\n",
    "plt.ylabel(\"Number of Passengers\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing people who lived or died, based upon gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived = X_train[y_train == 1]\n",
    "died = X_train[y_train == 0]\n",
    "\n",
    "print \"SURVIVORS\"\n",
    "print survived[\"Sex\"].value_counts()\n",
    "print survived[\"Sex\"].value_counts() / len(survived)\n",
    "print \"\"  # Newline\n",
    "\n",
    "print \"PEOPLE WHO DIED\"\n",
    "print died[\"Sex\"].value_counts()\n",
    "print died[\"Sex\"].value_counts() / len(died)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing people who lived or died, based upon which port they came from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "survived = X_train[y_train == 1]\n",
    "died = X_train[y_train == 0]\n",
    "\n",
    "print \"SURVIVORS\"\n",
    "print survived[\"Embarked\"].value_counts()\n",
    "print survived[\"Embarked\"].value_counts() / len(survived)\n",
    "print \"\"  # Newline\n",
    "\n",
    "print \"PEOPLE WHO DIED\"\n",
    "print died[\"Embarked\"].value_counts()\n",
    "print died[\"Embarked\"].value_counts() / len(died)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The distribution overall looks the same... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a baseline classifier that we want to beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode the categorical variables\n",
    "_X_train = pd.get_dummies(X_train, columns=[\"Pclass\", \"Sex\", \"Embarked\"])\n",
    "_X_test = pd.get_dummies(X_test, columns=[\"Pclass\", \"Sex\", \"Embarked\"])\n",
    "\n",
    "# Only doing this beacuse encoding might not be preserved\n",
    "# This checks that the column of the training and test set are aligned\n",
    "assert (_X_train.columns == _X_test.columns).all()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = SVC().fit(_X_train, y_train).predict(_X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Let's try scaling some features now.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(_X_train[\"Fare\"])\n",
    "_X_train[\"Fare\"] = scaler.transform(_X_train[\"Fare\"])\n",
    "_X_test[\"Fare\"] = scaler.transform(_X_test[\"Fare\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = SVC().fit(_X_train, y_train).predict(_X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting over... \n",
    "\n",
    "We dropped the features \"PassengerId\", \"Age\", \"Cabin\", \"SibSp\", and \"Parch\". A good guess is that \"Age\" is a good indication of whether a passenger died or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [\"Pclass\", \"Sex\", \"Fare\", \"Embarked\", \"Survived\", \"Age\"]\n",
    "subset = data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = subset.drop(\"Survived\", axis=1)\n",
    "y = subset[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot a histogram of the ages\n",
    "# http://stackoverflow.com/a/6873956/2014591   <- plotting two histograms at once\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Way to change sizes of plots\n",
    "# http://stackoverflow.com/a/332311/2014591\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 5  \n",
    "\n",
    "survived = X_train[y_train == 1]\n",
    "died = X_train[y_train == 0]\n",
    "\n",
    "# Need to also drop NaN values\n",
    "survived = survived.dropna()\n",
    "died = died.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.hist\n",
    "plt.hist([died[\"Age\"], survived[\"Age\"]], alpha=0.5, color=['r', 'g'], label=[\"Survived\", \"Died\"], stacked=True)\n",
    "\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Number of Passengers\")\n",
    "plt.xlim(0, 100)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in missing values\n",
    "\n",
    "This is called [imputation](https://en.wikipedia.org/wiki/Imputation_(statistics). In this case, we're going to use the mean of the age to impute. There are other strategies for imputation.\n",
    "\n",
    "Ways to impute:\n",
    "* Scikit-Learn: [Imputer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Imputer.html) (Disclaimer: haven't gotten it to work yet)\n",
    "* Pandas: [DataFrame.fillna](http://pandas.pydata.org/pandas-docs/version/0.17.1/generated/pandas.DataFrame.fillna.html)\n",
    "\n",
    "We're going to fill the missing values using the *mean* of the ages.\n",
    "\n",
    "Imputation is an open research problem. There are various ways to go about imputing values, and not one of them is claimed to be the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the number of missing values first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train[\"Age\"].describe()  <-- Most version of pandas lets you see number of NaN values here, not old version\n",
    "len(X_train[\"Age\"]) - X_train[\"Age\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean = X_train[\"Age\"].describe()[\"mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train[\"Age\"].fillna(mean, inplace=True)\n",
    "X_test[\"Age\"].fillna(mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encode the categorical variables\n",
    "_X_train = pd.get_dummies(X_train, columns=[\"Pclass\", \"Sex\", \"Embarked\"])\n",
    "_X_test = pd.get_dummies(X_test, columns=[\"Pclass\", \"Sex\", \"Embarked\"])\n",
    "\n",
    "# Only doing this beacuse encoding might not be preserved\n",
    "# This checks that the column of the training and test set are aligned\n",
    "assert (_X_train.columns == _X_test.columns).all()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0).fit(_X_train, y_train)\n",
    "predictions = clf.predict(_X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
